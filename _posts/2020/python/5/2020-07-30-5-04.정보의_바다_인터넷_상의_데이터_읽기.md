---
layout: post
title: "[Python데이터분석] 4. 정보의 바다, 인터넷 상의 데이터 읽기"
description: " "
date: 2020-07-29
tags: [Python]
comments: true
share: true
---


## URL상의 CSV 읽기

- pandas.read_csv(url)

## 직접 크롤링을 통한 읽기

- request/Selenium 라이브러리를 통한 처리
- pandas.read_html(url,...): 내부적으로 requests 라이브러리 활용

## pandas-datareader 라이브러리

- 내부적으로 requests 라이브러리 활용
  - 지원 데이터 소스: FRED, Nasdaq, Yahoo Finance, Google Finance 등
- 정식 API가 아닌 크롤링을 사용하는 것이기에 버전에 따라 오류 발생 가능

## seaborn 라이브러리

- [예제용 저장소]

## pandas.read_csv

- [Kosdaq 종목코드 CSV URL]
- [Kospi 종목코드 CSV URL] - 현재 사용불가

## pandas.read_html

- 웹페이지 크롤링을 쉽게 도와주는 라이브러리 -> 만능 X
- 웹 페이지상의 HTML table을 한번에 로딩하기 위한 목적
- HTML table에 데이터 외에 다른 문자열이 있을 경우 곤란

> 직접 크롤링하는 것이 간편

## Pandas-datareader

- 최신 버전 업그레이드 필수

```bash
pip install --upgrade pandas-datareader
```

[예제용 저장소]: https://github.com/mwaskom/seaborn-data
[Kosdaq 종목코드 CSV URL]: https://gist.githubusercontent.com/allieus/5ce98166166d06ee9060e6a261e812dc/raw
[Kospi 종목코드 CSV URL]: https://goo.gl/aUHznc

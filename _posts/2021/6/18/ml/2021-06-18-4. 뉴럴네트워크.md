---
layout: post
title: "[머신러닝] 4. 뉴럴네트워크"
description: " "
date: 2021-06-18
tags: [머신러닝]
comments: true
share: true
---

## 뉴럴네트워크

## 퍼셉트론(Perceptron)

### 단층 퍼셉트론 : 초기 뉴럴 네트워크
- 입력값의 선형결합 값을 구하고 그 값이 0보다 큰지 분류
- 단층 퍼셉트론으로는 모든 문제를 해결할 수 없다.

![image](https://user-images.githubusercontent.com/79880336/111060879-73ca1c00-84e3-11eb-9499-fe311cbbff47.png)


![image](https://user-images.githubusercontent.com/79880336/111060872-67de5a00-84e3-11eb-8a56-df59c4127604.png)

(XOR 연산의 경우 단층 퍼셉트론으로는 구별할 수 없다)
 
### 2중 퍼셉트론 (=뉴럴 네트워크)
- 두 개의 퍼셉트론을 결합
- 두 개의 입력변수와 한 개의 출력변수
- 로지스틱 모델을 다시 한 번 로지스틱 모델로 구성한 형태

![image](https://user-images.githubusercontent.com/79880336/111063929-9fa1cd80-84f4-11eb-91f8-22a9324eb116.png)

### 다층 퍼셉트론 (Multilayer Perecptron)

![image](https://user-images.githubusercontent.com/79880336/111063972-e68fc300-84f4-11eb-9ca8-ed1a9c35ad2d.png)

#### 선형회귀모델, 로지스틱회귀모델, 뉴럴네트워크모델

![image](https://user-images.githubusercontent.com/79880336/111064008-176ff800-84f5-11eb-9825-6857a16b446a.png)
 
(뉴럴네트워크 파라미터가 많아짐)

### 뉴럴네트워크 파라미터

![image](https://user-images.githubusercontent.com/79880336/111064047-4b4b1d80-84f5-11eb-9f40-2cd05900e98a.png)

### Activation Function (활성화 함수)

![image](https://user-images.githubusercontent.com/79880336/111064115-9fee9880-84f5-11eb-9684-3c462f35791f.png)

#### 시그모이드 함수(Sigmoid Function)

![image](https://user-images.githubusercontent.com/79880336/111064139-c44a7500-84f5-11eb-8d29-43533bd976b4.png)

### 뉴럴네트워크 파라미터 결정, 비용함수

![image](https://user-images.githubusercontent.com/79880336/111064169-e3490700-84f5-11eb-8aab-229b0d4081f1.png)

  #### 뉴럴네트워크 비용함수 - 수치예측

![image](https://user-images.githubusercontent.com/79880336/111064226-21dec180-84f6-11eb-95c6-9fc8986b1cd8.png)

(MSE : 오차가 커질수록 손실함수가 빠르게 증가하는 특징이 있다.)

![image](https://user-images.githubusercontent.com/79880336/111064253-505c9c80-84f6-11eb-9ab9-3ef7dec18228.png)

(CEE : 정확히 맞추면 오차가 0. 틀릴수록 오차가 무한히 증가하는 특징이 있다.)


  #### 뉴럴네트워크 학습 - 경사하강법

![image](https://user-images.githubusercontent.com/79880336/111064305-99145580-84f6-11eb-83bb-9728a6830613.png)

- 경사하강법 (Gradient Descent Method)

![image](https://user-images.githubusercontent.com/79880336/111064335-cc56e480-84f6-11eb-85f5-b8bf404c41f4.png)

- 학습률의 선택
 
![image](https://user-images.githubusercontent.com/79880336/111064339-d37df280-84f6-11eb-9e86-33cfe957cee6.png)

![image](https://user-images.githubusercontent.com/79880336/111071715-d094f900-851a-11eb-8ef0-f0ff4d7aee8b.png)

적절한 학습률(Learning rate)을 선택하는 것은 매우 중요하다

참고:
https://sihyeon-kim.github.io/neural-networks-and-deep-learning-korean/chapter1.html

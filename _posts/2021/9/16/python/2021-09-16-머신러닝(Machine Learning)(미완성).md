---
layout: post
title: "[파이썬] 머신러닝(Machine Learning)"
description: " "
date: 2021-09-16
tags: [파이썬]
comments: true
share: true
---

## 머신러닝(Machine Learning)

## 머신러닝 시스템의 종류

### 1. 지도학습

지도학습(supervised learning)에는 알고리즘에 주입하는 훈련 데이터에 **레이블**이라는 원하는 답이 포함된다. ( training set 과 testing set 이 있다.)

**분류(classification)** 가 전형적인 지도 학습 작업이며, **스팸필터가 좋은 예시**이다. 스팸필터는 많은 메일 샘플과 소속 정보(스팸인지 아닌지) 로 훈련되어야 하며 어떻게 새 메일을 분류할지 학습해야 한다.

또 다른 작업은 **예측 변수(predictor variable)** 이라 부르는 **특성(feature)**(주행거리,연식,브랜드 등)을 사용해 중고차 가격타깃 수치를 예측하는 것. 이런 종류의 작업을 회귀(regression)라 부른다.

일부 회귀 알고리즘은 분류에 사용할 수도 있고 또 반대의 경우도 있다. 예를 들면 분류에 널리쓰이는 **로지스틱회귀**는 클래스에 속할 확률을 출력한다. (예, 스팸일 가능성 20%)

지도학습중 자주 쓰이는 알고리즘

- k-최근접 이웃 (k-Nearest Neighbors) - KNN
- 선형회귀 (Linear Regression)
- 로지스틱회귀(Logistic Regression)
- 서포트 벡터 머신(Support Vector Machines) - SVM
- 결정트리(Decision Tree), 랜덤 포레스트(Random Forests)
- 신경망(Neural networks)

### 2. 비지도학습

비지도학습(unsupervised learning)에는 말 그대로 훈련 데이터에 레이블이 없다. 시스템이 아무런 도움 없이 학습해야함, 즉 원인과 결과로 예측을 하던 지도학습과 다르게 결과가 없이 비슷한 데이터들을 정리해 데이터의 특징을 파악하는 내용이라 생각된다.

비지도학습중 자주 쓰이는 알고리즘

예를 들어 블로그 방문자에 대한 데이터를 비슷한 방문자들끼리 그룹을 만들고싶을때, 방문자가 어떤 그룹에 속하는지 알수 있는 포인트가 없다. 그래서 알고리즘이 스스로 방문자 사이의 연결고리를 찾는다. 예를 들어 40%의 방문자가 만화책을 좋아하며 저녁때 블로그 글을 읽는 남성이고, 20% 는 주말에 방문하는 공상 과학을 좋아하는 젊은 사람임을 알게 될지도 모른다. **계층 군집** 알고리즘을 사용하면 각 그룹을 더 작은 그룹으로 세분화할 수 있다.

**시각화**(visualization) 알고리즘도 비지도 학습 알고리즘의 좋은 예이다. 레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D 나 3D 표현을 만들어줍니다. 이런 알고리즘은 가능한 한 구조를 그대로 유지하려 하므로 데이터가 어떻게 형성되있는지 이해할 수 있고 예상치 못한 패턴을 찾을 수 있다.

**차원 축소**(dimensionality reduction)라는 작업도 있다. 간략히 말해 데이터를 너무 많이 잃지 않으면서 데이터를 간소화하려는 작업이 **차원 축소**이다. 차원 축소 중 하나의 방법은 상관관계가 있는 여러 특성을 하나로 합치는 것이다. 예를 들어 차의 주행거리는 연식과 매우 연관되어 있으므로 차원 축소 알고리즘으로 두 특성을 차의 마모 정도를 나타내는 하나의 특성으로 합칠 수 있다. 이를 **특성 추출(feature extraction)**이라 한다.

차원 축소는 지도 학습 알고리즘에 데이터를 주입하기전에 하면 유용할 때가 많다.

**군집**

- k-평균(K-Means)
- 계층 군집 분석(Hierarchical Cluster Analysis) - HCA
- 기댓값 최대화(Expectation Maximiztion)

**시각화와 차원축소**

- 주성분 분석(Principal Component Analysis) - PCA
- 커널 PCA
- 지역적 선형 임베딩(Locally-Linear Embedding) - LLE
- t-SNE(t-distributed Stochastic Neighbor Embedding)

**연관 규칙 학습**

- 어프라이어리(Apriori) - 장바구니분석
- 이클렛(Eclat)

또 하나 중요한 비지도학습은 **이상치 탐지**(anomaly detection)이다. 좋은 예는 부정거래를 막기 위해 이상한 신용카드 거래를 감지하고, 제조 결함을 잡아내고, 학습 알고리즘에 주입하기 전에 데이터셋에 이상한 값을 자동으로 제거하는 것 등이 있다.시스템은 정장 샘플로 훈련되고, 새로운 샘플이 정상데이터인지 혹은 이상치인지 판단한다.

또 많이 쓰이는 비지도학습은 데이터에서 특성 간의 흥미로운 관계를 찾는 **연관 규칙 학습**(association rule learning)이다.예를 들어 상추와 소주를 구매한 사람이 삼겹살도 구매하는 경향이 있다라는 것을 찾을 수 있다.

### 3. 준지도 학습(semisupervised learning)

어떤 알고리즘은 레이블이 일부만 있는 데이터도 다룰 수 있다. 보통은 레이블이 없는 데이터가 많고 레이블이 있는 데이터는 아주 조금이다. 이를 **준지도 학습**이라 한다.

구글 포토 호스팅 서비스가 그 중 하나이다. 이 서비스에 가족사진을 모두 올리면 사람 A는 사진 1,5,11 에 있고, 사람 B는 3,5,7 에 있다고 자동으로 인식한다. 이는 비지도학습이다. 이제 시스템에 필요한건 이 사람들의 정보이다. 사람마다 레이블이 주어지면 사진에 있는 모든 사람의 이름을 알 수있고, 편리하게 사진을 찾을 수 있다. 물론 시스템이 완벽했을 경우에 해당한다.

대부분의 준지도 학습은 비지도, 지도 학습의 조합으로 이루어져 있다. 예를 들면 **심층 신뢰 신경망**(Deep Belief Network - DBN)은 여러 겹으로 쌓은 **제한된 볼츠만 머신**(Restricted Boltzmann Machine - RBM)이라 불리는 비지도 학습에 기초한다. RBM이 비지도 학습 방식으로 순차적으로 훈련된 다음 전체 시스템이 지도 학습 방식으로 세밀하게 조정된다.

### 4. 강화 학습(Reinforcement Learning)

강화학습은 매우 다른 종류의 알고리즘이다. 여기서 학습하는 시스템을 **에이전트**라고 부르며 환경을 관찰해서 행동을 실행하고 그 결과로 **보상** 또는 **벌점**을 받는다. 시간이 지나면서 가장 큰 보상을 얻기 위해 **정책**(policy)이라고 부르는 최상의 전략을 스스로 학습한다. 정책은 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지 정의한다.

한마디로 어떠한 **행동**을 엄청나게 많은 반복을 통해 그에 따른 결과로 **보상**이나 **벌점**을 받아 보상을 더욱 많이 받는 행동(**정책**)을 찾아 해매는 거로 생각된다.

- 에이전트, 환경, 행동, 보상, 벌점, 정책 등 용어가 있다.
- 보행 로봇 만들기, 딥마인드의 알파고 프로그램 등 강화학습의 좋은 예이다.

## 배치 학습과 온라인 학습

머신러닝 시스템을 분류하는 데 사용하는 다른 기준은 입력 데이터의 스트림(stream)으로부터 점진적으로 학습할 수 있는지 여부이다.

### 1. 배치 학습(batch learning) 

배치학습에서는 시스템이 점진적으로 학습을 할 수 없다. 가용한 데이터를 모두 사용해 훈련시켜야 한다. 일반적으로 이 방식은 시간과 자원을 많이 소모하므로 보통 오프라인에서 수행된다. 더 이상 학습없이 실행된다. **즉, 학습한 것을 단지 적용만 한다.** 이를 **오프라인 학습**(offline learning)이라고 한다.

배치 학습 시스템이 새로운 데이터에 대해 학습하려면 기존 데이터와 새로운 데이터를 포함해 다시 학습을 해야한다. 그런 다음 이전 시스템을 중지시키고 새 시스템으로 교체해야 한다.

위와 같이 데이터셋 전체를 이용해 훈련을 한다면 많은 컴퓨팅 자원이 필요하기 때문에 많은 시간과 큰 비용이 필요하다.따라서 데이터가 엄청 많으면 배치 학습 알고리즘을 사용하는게 불가능할 수도 있다.

### 2. 온라인 학습(online learning)

온라인 학습에서는 데이터를 순차적으로 한 개씩 또는 **미니배치**(mini-batch)라 부르는 작은 묶음 단위로 주입하며 시스템을 훈련시킨다. 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있다.

온라인 학습은 연속적으로 데이터를 받고 빠른 변화에 스스로 적응해야하는 시스템에 적합하다. (예를 들면 주식가격)    컴퓨팅 자원이 제한된 경우에도 좋은 선택이다. 온라인 학습 시스템이 새로운 데이터 샘플을 학습하면 학습이 끝난 데이터는 더 이상 필요하지 않으므로 버리거나 다른 곳에 백업해 두어도 된다. 

컴퓨터 한 대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템에도 온라인 학습 알고리즘을 사용할 수 있다.( 이를 **외부 메모리** 학습이라고 한다, out-of-core learning) 알고리즘이 데이터 일부를 읽어들이고 훈련 단계를 수행한다. 전체 데이터가 모두 적용될 때까지 이 과정을 반복한다. 이 경우는 보통 오프라인에서 실행된다.(이 경우는 실시간으로 수행되는 것이 아니다.)

온라인 학습 시스템에서 중요한 파라미터 하나는 변화하는 데이터에 얼마나 빠르게 적응할 것 인지이다. 이를 **학습률**(learning rate)이라 한다. 학습률을 높게 하면 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버릴 것이다. (예를 들면 최신 스팸메일만 걸러내는 시스템이 된다라는 뜻) 반대로 학습률이 낮으면 시스템의 관성이 더 커져서 더 느리게 학습하게된다. 하지만 새로운 데이터에 잡음이나 대표성 없는 데이터 포인트에 덜 민감해진다.(새로운 데이터와 구 데이터를 어느정도 학습하지만 실시간으로 하기 어려울 수 있다라는 것같다.)

온라인 학습에서 가장 큰 문제점은 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 점진적으로 감소한다. 운영 중인 시스템이라면 고객이 눈치챌 수 있다. 예를 들어 로봇의 오작동 센서로부터, 혹은 검색 엔진을 속여 검색 결과 상위에 노출시키려는 누군가로부터 나쁜 데이터가 들어 올 수 있다. 이런 위험을 줄이려면 시스템을 면밀히 모니터링하고 성능 감소가 감지되면 즉각 학습을 중단시켜야한다. 입력 데이터를 모니터링해서 비정상 데이터를 잡아낼 수도 있다. 이상탐지 알고리즘을 사용하여 잡아낼 수 있다.

## 사례 기반 학습과 모델 기반 학습

머신러닝은 어떻게 **일반화**되는가에 따라 분류할 수 있다. 대부분 머신러닝은 예측을 만드는 것이다. 주어진 훈련 데이터로 학습하지만 훈련 데이터에서는 본적 없는 새로운 데이터로 일반화되어야 한다는 뜻이다. 훈련데이터에서 높은 성능을 내는 것이 좋지만 마냥 좋은건 아니다. 진짜 목표는 새로운 샘플에 얼마나 좋은 성능을 가지는 모델인가 ?이다.

일반화를 위한 두가지 접근법은 사례 기반 학습, 모델 기반 학습이 있다.

### 1. 사례 기반 학습(instance-based learning)

스팸 메일을 예시로 스팸 메일과 동일한 메일을 스팸이라고 지정하는 대신 스팸 메일과 매우 유사한 메일을 구분하도록 스팸 필터를 프로그램할 수 있다. 이렇게 하려면 두 메일 사이의 **유사도(similarity)**를 측정해야한다. 두 메일 사이의 매우 간단한 유사도 측정 방법은 공통으로 포함한 단어의 수를 세는 것이다. 스팸 메일과 공통으로 가지고 있는 단어가 많으면 스팸으로 분류한다. **이를 사례 기반 학습**이라 한다. 시스템이 사례를 기억함으로써 학습한다. 그리고 유사도 측정을 사용해 새로운 데이터를 일반화한다.

### 2. 모델 기반 학습(model-based learning)

샘플로부터 일반화시키는 다른 방법은 이 샘플들의 모델을 만들어 **예측**에 사용하는 것이다. 이를 **모델 기반 학습**이라 한다.
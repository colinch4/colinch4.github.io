---
layout: post
title: "[Python] Data sampling"
description: " "
date: 2023-09-10
tags: [basic]
comments: true
share: true
---

Data sampling is a method used in data analysis to select a subset of data from a larger population. This subset, known as a sample, is representative of the entire population and allows for analysis and inference without having to process the entire dataset.

In Python, there are multiple libraries and techniques available to perform data sampling. In this blog post, we will explore some of these methods and provide example code to demonstrate their usage.

## 1. Random Sampling

Random sampling is a simple and commonly used method to create a sample from a dataset. The `random` module in Python provides functions to generate random numbers, which can be utilized for random sampling.

Here's an example code snippet that demonstrates random sampling in Python:

```python
import random

data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

sample_size = 5
sample = random.sample(data, sample_size)

print(sample)
```

In the above code, we have a dataset of numbers ranging from 1 to 10. By using the `random.sample` function, we select 5 random numbers from the dataset and store them in the `sample` variable. Finally, we print the sample to the console.

## 2. Stratified Sampling

Stratified sampling is a method to obtain a sample that accurately represents the different subgroups or strata within a population. This technique ensures that each stratum is well-represented in the final sample.

The `scikit-learn` library in Python provides a `StratifiedShuffleSplit` class, which can be used for stratified sampling. Here's an example code snippet that demonstrates stratified sampling using `scikit-learn`:

```python
from sklearn.model_selection import StratifiedShuffleSplit

data = [...]  # Your dataset

target = [...]  # Target variable

stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)

for train_index, test_index in stratified_split.split(data, target):
    train_set = data[train_index]
    test_set = data[test_index]
```

In the above code, we first define our dataset (`data`) and the corresponding target variable (`target`). Then, we create an instance of `StratifiedShuffleSplit` and specify the desired number of splits (`n_splits`), the test size (`test_size`), and a random state for reproducibility. Finally, we iterate over the generated splits and obtain the training and testing sets.

## 3. Reservoir Sampling

Reservoir sampling is a technique used to obtain a random sample of a specific size from a large or unknown dataset. This method is memory-efficient and does not require iterating over the entire dataset.

Here's an example code snippet that demonstrates reservoir sampling in Python:

```python
import random

def reservoir_sampling(data, sample_size):
    reservoir = []

    # Fill the reservoir with the first sample_size elements from the data
    for i in range(sample_size):
        reservoir.append(data[i])

    n = len(data)

    # Replace elements in the reservoir with decreasing probability
    for i in range(sample_size, n):
        j = random.randint(0, i)
        if j < sample_size:
            reservoir[j] = data[i]

    return reservoir

data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
sample_size = 5

sample = reservoir_sampling(data, sample_size)

print(sample)
```

In the above code, the `reservoir_sampling` function implements the reservoir sampling algorithm. It takes the dataset (`data`) and the desired sample size (`sample_size`) as inputs and returns the sampled elements. The function fills the reservoir with the first `sample_size` elements from the data and then replaces elements in the reservoir with decreasing probability.

These are just a few methods for data sampling in Python. Each method has its own advantages and use cases, depending on the nature of the data and the analysis objectives. By using appropriate sampling techniques, you can efficiently analyze large datasets and make informed decisions based on smaller representative samples.